{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akram 1\\AppData\\Local\\Temp\\ipykernel_13504\\2392206408.py:10: DtypeWarning: Columns (32,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path, sep='|')\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data from .txt format (assuming it's tab-separated or comma-separated)\n",
    "file_path = '../data/MachineLearningRating_v3.txt'\n",
    "\n",
    "df = pd.read_csv(file_path, sep='|')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['UnderwrittenCoverID', 'PolicyID', 'TransactionMonth',\n",
      "       'IsVATRegistered', 'Citizenship', 'LegalType', 'Title', 'Language',\n",
      "       'Bank', 'AccountType', 'MaritalStatus', 'Gender', 'Country', 'Province',\n",
      "       'PostalCode', 'MainCrestaZone', 'SubCrestaZone', 'ItemType', 'mmcode',\n",
      "       'VehicleType', 'RegistrationYear', 'make', 'Model', 'Cylinders',\n",
      "       'cubiccapacity', 'kilowatts', 'bodytype', 'NumberOfDoors',\n",
      "       'VehicleIntroDate', 'CustomValueEstimate', 'AlarmImmobiliser',\n",
      "       'TrackingDevice', 'CapitalOutstanding', 'NewVehicle', 'WrittenOff',\n",
      "       'Rebuilt', 'Converted', 'CrossBorder', 'NumberOfVehiclesInFleet',\n",
      "       'SumInsured', 'TermFrequency', 'CalculatedPremiumPerTerm',\n",
      "       'ExcessSelected', 'CoverCategory', 'CoverType', 'CoverGroup', 'Section',\n",
      "       'Product', 'StatutoryClass', 'StatutoryRiskType', 'TotalPremium',\n",
      "       'TotalClaims', 'Profit', 'ClaimRatio', 'VehicleAge'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print (df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Summarization:\n",
    "## Descriptive Statistics\n",
    "print(\"Descriptive Statistics:\")\n",
    "numerical_columns = ['TotalPremium', 'TotalClaims']\n",
    "print(df[numerical_columns].describe())\n",
    "\n",
    "# Variability (Standard deviation) for numerical features\n",
    "print(\"\\nVariability (Standard Deviation):\")\n",
    "print(df[numerical_columns].std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the data from .txt format (assuming it's tab-separated or comma-separated)\n",
    "file_path = '../data/MachineLearningRating_v3.txt'\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(file_path, sep='|')\n",
    "\n",
    "# Inspect the first few rows of 'TransactionMonth' and 'VehicleIntroDate' to understand their format\n",
    "print(\"TransactionMonth sample:\\n\", df['TransactionMonth'].head())\n",
    "print(\"VehicleIntroDate sample:\\n\", df['VehicleIntroDate'].head())\n",
    "\n",
    "# Attempt to convert date columns to appropriate formats\n",
    "# Adjust format based on the actual format of your data\n",
    "try:\n",
    "    df['TransactionMonth'] = pd.to_datetime(df['TransactionMonth'], format='%Y-%m', errors='coerce')\n",
    "except Exception as e:\n",
    "    print(f\"Error converting 'TransactionMonth': {e}\")\n",
    "\n",
    "try:\n",
    "    df['VehicleIntroDate'] = pd.to_datetime(df['VehicleIntroDate'], errors='coerce')\n",
    "except Exception as e:\n",
    "    print(f\"Error converting 'VehicleIntroDate': {e}\")\n",
    "\n",
    "# Descriptive Statistics: Calculating Variability for numerical columns\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "descriptive_stats = df[numeric_cols].describe()\n",
    "\n",
    "# Variability metrics\n",
    "variability = df[numeric_cols].agg(['std', 'var', lambda x: x.max() - x.min()])\n",
    "\n",
    "# Rename the last row to 'range'\n",
    "variability.index = ['std', 'var', 'range']\n",
    "\n",
    "print(\"Descriptive Statistics:\\n\", descriptive_stats)\n",
    "print(\"\\nVariability (Standard Deviation, Variance, Range):\\n\", variability)\n",
    "\n",
    "# Check data structure: dtypes of each column\n",
    "dtypes_info = df.dtypes\n",
    "\n",
    "print(\"\\nData Structure (Dtypes):\\n\", dtypes_info)\n",
    "\n",
    "# Check if categorical columns are properly formatted\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(\"\\nCategorical Columns:\\n\", categorical_cols)\n",
    "\n",
    "# Convert specific columns to categorical dtype\n",
    "categorical_cols_to_convert = [\n",
    "    'Citizenship', 'LegalType', 'Title', 'Language',\n",
    "    'Bank', 'AccountType', 'MaritalStatus', 'Gender',\n",
    "    'Country', 'Province', 'MainCrestaZone',\n",
    "    'SubCrestaZone', 'ItemType', 'mmcode', 'VehicleType',\n",
    "    'bodytype', 'CoverCategory', 'CoverType', 'CoverGroup',\n",
    "    'Section', 'Product', 'StatutoryClass', 'StatutoryRiskType'\n",
    "]\n",
    "\n",
    "# Ensure that the columns exist before converting\n",
    "for col in categorical_cols_to_convert:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "# Confirm dtype after conversion\n",
    "print(\"\\nUpdated Data Structure (Dtypes after conversion):\\n\", df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_values = missing_values[missing_values > 0]\n",
    "print(\"Missing Values Summary:\\n\", missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot histograms for numerical columns\n",
    "numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "for i, col in enumerate(numerical_cols, 1):\n",
    "    plt.subplot(4, 5, i)  # Adjust the number of rows and columns according to your data\n",
    "    sns.histplot(df[col], kde=True, bins=50)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get the categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['category']).columns\n",
    "\n",
    "# Determine the number of rows and columns needed\n",
    "num_cols = len(categorical_cols)\n",
    "num_rows = (num_cols + 2) // 3  # Adds enough rows to fit all columns\n",
    "\n",
    "# Create a figure with the appropriate size\n",
    "plt.figure(figsize=(14, num_rows * 5))  # Adjust height as needed\n",
    "\n",
    "# Plot each categorical column\n",
    "for i, col in enumerate(categorical_cols, 1):\n",
    "    plt.subplot(num_rows, 4, i)  # Adjust rows and columns based on the number of categorical columns\n",
    "    sns.countplot(y=df[col].dropna(), order=df[col].value_counts().index)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.xlabel('Frequency')\n",
    "    plt.ylabel(col)\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Scatter plot for TotalPremium vs TotalClaims using Province as the hue\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(x='TotalPremium', y='TotalClaims', hue='Province', data=df)\n",
    "plt.title('Scatter Plot of TotalPremium vs TotalClaims by Province')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix for numerical variables (TotalPremium and TotalClaims)\n",
    "correlation_matrix = df[['TotalPremium', 'TotalClaims']].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.title('Correlation Matrix of TotalPremium and TotalClaims')\n",
    "plt.show()\n",
    "\n",
    "# Correlation matrix for TotalPremium and TotalClaims\n",
    "correlation_matrix = df[['TotalPremium', 'TotalClaims']].corr()\n",
    "print(\"\\nCorrelation Matrix:\\n\", correlation_matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot distribution of insurance cover type by province\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.countplot(data=df, y='CoverType', hue='Province', order=df['CoverType'].value_counts().index)\n",
    "plt.title('Distribution of Insurance Cover Types Across Provinces')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Cover Type')\n",
    "plt.legend(title='Province', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='make', y='CalculatedPremiumPerTerm', data=df, palette='Set2')\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Premium Distribution by Auto Make')\n",
    "plt.xlabel('Auto Make')\n",
    "plt.ylabel('Calculated Premium Per Term')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Data Comparison: Trends Over Geography\n",
    "\n",
    "# Compare average TotalPremium by Province\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Province', y='TotalPremium', data=df, estimator='mean', palette='viridis')\n",
    "plt.title('Average TotalPremium by Province')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Compare average Count of Auto Makes by Province\n",
    "auto_make_count = df.groupby(['Province', 'make']).size().reset_index(name='Count')\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x='Province', y='Count', hue='make', data=auto_make_count, palette='Set2')\n",
    "plt.title('Auto Make Count by Province')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping by Province and summing the counts of each make\n",
    "auto_make_count = df.groupby(['Province', 'make']).size().reset_index(name='Count')\n",
    "\n",
    "# Pivot the table to get data in a more suitable format for a stacked bar chart\n",
    "auto_make_pivot = auto_make_count.pivot(index='Province', columns='make', values='Count').fillna(0)\n",
    "\n",
    "# Plotting the stacked bar chart\n",
    "plt.figure(figsize=(14, 8))\n",
    "auto_make_pivot.plot(kind='bar', stacked=True, figsize=(14, 8), cmap='Set2')\n",
    "\n",
    "# Customizing the plot\n",
    "plt.title('Auto Make Count by Province', fontsize=16)\n",
    "plt.ylabel('Count', fontsize=12)\n",
    "plt.xticks(rotation=45, ha='right', fontsize=10)\n",
    "plt.xlabel('Province', fontsize=12)\n",
    "\n",
    "# Adding legend and labels\n",
    "plt.legend(title='Make', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Outlier Detection: Box Plots\n",
    "\n",
    "# Box plot for TotalPremium\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='TotalPremium', data=df, color='lightcoral')\n",
    "plt.title('Box Plot of TotalPremium')\n",
    "plt.show()\n",
    "\n",
    "# Box plot for TotalClaims\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.boxplot(x='TotalClaims', data=df, color='lightblue')\n",
    "plt.title('Box Plot of TotalClaims')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a pivot table for the heatmap\n",
    "pivot_table = df.pivot_table(values='CalculatedPremiumPerTerm', index='make', columns='Province', aggfunc='mean')\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(pivot_table, cmap='coolwarm', annot=True, fmt=\".1f\", linewidths=.5)\n",
    "plt.title('Average Insurance Premiums by Vehicle Make and Region')\n",
    "plt.xlabel('Province')\n",
    "plt.ylabel('Vehicle Make')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create the FacetGrid\n",
    "g = sns.FacetGrid(df, col=\"VehicleType\", col_wrap=4, height=4, sharex=False, sharey=True)\n",
    "g.map(sns.histplot, \"CalculatedPremiumPerTerm\", bins=30, kde=True, color=\"blue\")\n",
    "g.set_axis_labels('Premium', 'Frequency')\n",
    "g.set_titles(col_template=\"{col_name}\")\n",
    "g.add_legend()\n",
    "plt.suptitle('Distribution of Insurance Premiums by Vehicle Type', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "sns.boxplot(x='CoverType', y='TotalClaims', data=df, palette='Set2')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Distribution of Total Claims by Cover Type')\n",
    "plt.xlabel('Cover Type')\n",
    "plt.ylabel('Total Claims')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# Grouping data by Province and calculating mean claims\n",
    "grouped_by_province = df.groupby('Province')['TotalClaims']\n",
    "\n",
    "# One-way ANOVA test\n",
    "anova_result = f_oneway(*[group for _, group in grouped_by_province])\n",
    "print(\"ANOVA test for risk differences across provinces: \", anova_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping data by PostalCode\n",
    "grouped_by_postal = df.groupby('PostalCode')['TotalClaims']\n",
    "\n",
    "# ANOVA test for multiple postal codes\n",
    "anova_result_postal = f_oneway(*[group for _, group in grouped_by_postal])\n",
    "\n",
    "# Output the ANOVA results\n",
    "print(\"ANOVA Result for TotalClaims across PostalCodes:\")\n",
    "print(anova_result_postal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "\n",
    "# Define the KPI: Risk (TotalClaims) and Margin (TotalPremium - TotalClaims)\n",
    "df['Margin'] = df['TotalPremium'] - df['TotalClaims']\n",
    "\n",
    "# 1. Hypothesis: No Risk Differences Across Provinces\n",
    "group_a_province = df[df['Province'] == 'A']['TotalClaims']  # Replace 'A' with a province\n",
    "group_b_province = df[df['Province'] == 'B']['TotalClaims']  # Replace 'B' with another province\n",
    "\n",
    "# Check for normality\n",
    "shapiro_a = stats.shapiro(group_a_province)\n",
    "shapiro_b = stats.shapiro(group_b_province)\n",
    "\n",
    "# Perform t-test or Mann-Whitney U test based on normality\n",
    "if shapiro_a.pvalue > 0.05 and shapiro_b.pvalue > 0.05:\n",
    "    t_stat, p_value = stats.ttest_ind(group_a_province, group_b_province)\n",
    "else:\n",
    "    u_stat, p_value = stats.mannwhitneyu(group_a_province, group_b_province)\n",
    "\n",
    "# Interpretation\n",
    "print(f\"Risk Differences Across Provinces - p-value: {p_value}\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Reject the null hypothesis: There are significant risk differences across provinces.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant risk differences across provinces.\")\n",
    "\n",
    "# 2. Hypothesis: No Risk Differences Between Zip Codes\n",
    "group_a_zip = df[df['PostalCode'] == 'A']['TotalClaims']  # Replace 'A' with a postal code\n",
    "group_b_zip = df[df['PostalCode'] == 'B']['TotalClaims']  # Replace 'B' with another postal code\n",
    "\n",
    "# Perform the same normality test and comparison\n",
    "shapiro_a_zip = stats.shapiro(group_a_zip)\n",
    "shapiro_b_zip = stats.shapiro(group_b_zip)\n",
    "\n",
    "if shapiro_a_zip.pvalue > 0.05 and shapiro_b_zip.pvalue > 0.05:\n",
    "    t_stat_zip, p_value_zip = stats.ttest_ind(group_a_zip, group_b_zip)\n",
    "else:\n",
    "    u_stat_zip, p_value_zip = stats.mannwhitneyu(group_a_zip, group_b_zip)\n",
    "\n",
    "print(f\"Risk Differences Between Zip Codes - p-value: {p_value_zip}\")\n",
    "if p_value_zip < 0.05:\n",
    "    print(\"Reject the null hypothesis: Significant risk differences between zip codes.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant risk differences between zip codes.\")\n",
    "\n",
    "# 3. Hypothesis: No Significant Margin Differences Between Zip Codes\n",
    "group_a_margin = df[df['PostalCode'] == 'A']['Margin']  # Replace 'A' with a postal code\n",
    "group_b_margin = df[df['PostalCode'] == 'B']['Margin']  # Replace 'B' with another postal code\n",
    "\n",
    "# Perform the same test for profit margin\n",
    "shapiro_a_margin = stats.shapiro(group_a_margin)\n",
    "shapiro_b_margin = stats.shapiro(group_b_margin)\n",
    "\n",
    "if shapiro_a_margin.pvalue > 0.05 and shapiro_b_margin.pvalue > 0.05:\n",
    "    t_stat_margin, p_value_margin = stats.ttest_ind(group_a_margin, group_b_margin)\n",
    "else:\n",
    "    u_stat_margin, p_value_margin = stats.mannwhitneyu(group_a_margin, group_b_margin)\n",
    "\n",
    "print(f\"Profit Margin Differences Between Zip Codes - p-value: {p_value_margin}\")\n",
    "if p_value_margin < 0.05:\n",
    "    print(\"Reject the null hypothesis: Significant profit margin differences between zip codes.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant profit margin differences between zip codes.\")\n",
    "\n",
    "# 4. Hypothesis: No Risk Differences Between Women and Men\n",
    "group_a_gender = df[df['Gender'] == 'Male']['TotalClaims']  # Group A: Males\n",
    "group_b_gender = df[df['Gender'] == 'Female']['TotalClaims']  # Group B: Females\n",
    "\n",
    "# Perform the same test for gender-based risk differences\n",
    "shapiro_a_gender = stats.shapiro(group_a_gender)\n",
    "shapiro_b_gender = stats.shapiro(group_b_gender)\n",
    "\n",
    "if shapiro_a_gender.pvalue > 0.05 and shapiro_b_gender.pvalue > 0.05:\n",
    "    t_stat_gender, p_value_gender = stats.ttest_ind(group_a_gender, group_b_gender)\n",
    "else:\n",
    "    u_stat_gender, p_value_gender = stats.mannwhitneyu(group_a_gender, group_b_gender)\n",
    "\n",
    "print(f\"Risk Differences Between Genders - p-value: {p_value_gender}\")\n",
    "if p_value_gender < 0.05:\n",
    "    print(\"Reject the null hypothesis: Significant risk differences between women and men.\")\n",
    "else:\n",
    "    print(\"Fail to reject the null hypothesis: No significant risk differences between women and men.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Assume df is your dataframe\n",
    "# 1. Risk Differences Across Provinces\n",
    "grouped_by_province = df.groupby('Province')['TotalClaims']\n",
    "anova_result_province = stats.f_oneway(*[group for _, group in grouped_by_province])\n",
    "print(\"ANOVA result for Provinces:\", anova_result_province)\n",
    "\n",
    "# 2. Risk Differences Between Postal Codes\n",
    "grouped_by_postal = df.groupby('PostalCode')['TotalClaims']\n",
    "anova_result_postal = stats.f_oneway(*[group for _, group in grouped_by_postal])\n",
    "print(\"ANOVA result for Postal Codes:\", anova_result_postal)\n",
    "\n",
    "# 3. Profit Margin Differences Between Postal Codes\n",
    "df['Profit'] = df['TotalPremium'] - df['TotalClaims']\n",
    "grouped_by_postal_margin = df.groupby('PostalCode')['Profit']\n",
    "anova_result_margin = stats.f_oneway(*[group for _, group in grouped_by_postal_margin])\n",
    "print(\"ANOVA result for Postal Codes (Profit):\", anova_result_margin)\n",
    "\n",
    "# 4. Risk Differences Between Men and Women\n",
    "grouped_by_gender = df.groupby('Gender')['TotalClaims']\n",
    "anova_result_gender = stats.f_oneway(*[group for _, group in grouped_by_gender])\n",
    "print(\"ANOVA result for Gender:\", anova_result_gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Assume df is your DataFrame\n",
    "\n",
    "# 1. Chi-Square Test for Risk Differences Across Provinces (Categorical Data)\n",
    "province_claims = pd.crosstab(df['Province'], df['TotalClaims'] > 0)\n",
    "chi2_province, p_province, _, _ = stats.chi2_contingency(province_claims)\n",
    "print(f\"Chi-Square Test for Provinces: p-value = {p_province}\")\n",
    "if p_province < 0.05:\n",
    "    print(\"Reject Null Hypothesis: Significant risk differences across provinces.\")\n",
    "else:\n",
    "    print(\"Fail to Reject Null Hypothesis: No significant risk differences across provinces.\")\n",
    "\n",
    "# 2. ANOVA Test for Risk Differences Between Postal Codes (Numerical Data)\n",
    "grouped_by_postal = df.groupby('PostalCode')['TotalClaims']\n",
    "anova_result_postal = stats.f_oneway(*[group for _, group in grouped_by_postal])\n",
    "print(f\"ANOVA Test for Postal Codes: p-value = {anova_result_postal.pvalue}\")\n",
    "if anova_result_postal.pvalue < 0.05:\n",
    "    print(\"Reject Null Hypothesis: Significant risk differences between postal codes.\")\n",
    "else:\n",
    "    print(\"Fail to Reject Null Hypothesis: No significant risk differences between postal codes.\")\n",
    "\n",
    "# 3. T-Test for Profit Differences Between Postal Codes\n",
    "df['Profit'] = df['TotalPremium'] - df['TotalClaims']\n",
    "postal_codes = df['PostalCode'].unique()\n",
    "group_a_profit = df[df['PostalCode'] == postal_codes[0]]['Profit']\n",
    "group_b_profit = df[df['PostalCode'] == postal_codes[1]]['Profit']\n",
    "t_stat_profit, p_value_profit = stats.ttest_ind(group_a_profit, group_b_profit, equal_var=False)\n",
    "print(f\"T-Test for Postal Code Profit Differences: p-value = {p_value_profit}\")\n",
    "if p_value_profit < 0.05:\n",
    "    print(\"Reject Null Hypothesis: Significant profit margin differences between postal codes.\")\n",
    "else:\n",
    "    print(\"Fail to Reject Null Hypothesis: No significant profit margin differences between postal codes.\")\n",
    "\n",
    "# 4. Chi-Square Test for Risk Differences Between Genders (Categorical Data)\n",
    "gender_claims = pd.crosstab(df['Gender'], df['TotalClaims'] > 0)\n",
    "chi2_gender, p_gender, _, _ = stats.chi2_contingency(gender_claims)\n",
    "print(f\"Chi-Square Test for Gender: p-value = {p_gender}\")\n",
    "if p_gender < 0.05:\n",
    "    print(\"Reject Null Hypothesis: Significant risk differences between men and women.\")\n",
    "else:\n",
    "    print(\"Fail to Reject Null Hypothesis: No significant risk differences between men and women.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "task -4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnderwrittenCoverID               0\n",
      "PolicyID                          0\n",
      "TransactionMonth                  0\n",
      "IsVATRegistered                   0\n",
      "Citizenship                       0\n",
      "LegalType                         0\n",
      "Title                             0\n",
      "Language                          0\n",
      "Bank                              0\n",
      "AccountType                       0\n",
      "MaritalStatus                     0\n",
      "Gender                            0\n",
      "Country                           0\n",
      "Province                          0\n",
      "PostalCode                        0\n",
      "MainCrestaZone                    0\n",
      "SubCrestaZone                     0\n",
      "ItemType                          0\n",
      "mmcode                            0\n",
      "VehicleType                       0\n",
      "RegistrationYear                  0\n",
      "make                              0\n",
      "Model                             0\n",
      "Cylinders                         0\n",
      "cubiccapacity                     0\n",
      "kilowatts                         0\n",
      "bodytype                          0\n",
      "NumberOfDoors                     0\n",
      "VehicleIntroDate                  0\n",
      "CustomValueEstimate               0\n",
      "AlarmImmobiliser                  0\n",
      "TrackingDevice                    0\n",
      "CapitalOutstanding                0\n",
      "NewVehicle                        0\n",
      "WrittenOff                        0\n",
      "Rebuilt                           0\n",
      "Converted                         0\n",
      "CrossBorder                       0\n",
      "NumberOfVehiclesInFleet     1000098\n",
      "SumInsured                        0\n",
      "TermFrequency                     0\n",
      "CalculatedPremiumPerTerm          0\n",
      "ExcessSelected                    0\n",
      "CoverCategory                     0\n",
      "CoverType                         0\n",
      "CoverGroup                        0\n",
      "Section                           0\n",
      "Product                           0\n",
      "StatutoryClass                    0\n",
      "StatutoryRiskType                 0\n",
      "TotalPremium                      0\n",
      "TotalClaims                       0\n",
      "Profit                            0\n",
      "ClaimRatio                   381484\n",
      "VehicleAge                        0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Akram 1\\AppData\\Local\\Temp\\ipykernel_13504\\52216806.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[col].fillna(df[col].mode()[0], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnderwrittenCoverID               0\n",
      "PolicyID                          0\n",
      "TransactionMonth                  0\n",
      "IsVATRegistered                   0\n",
      "Citizenship                       0\n",
      "LegalType                         0\n",
      "Title                             0\n",
      "Language                          0\n",
      "Bank                              0\n",
      "AccountType                       0\n",
      "MaritalStatus                     0\n",
      "Gender                            0\n",
      "Country                           0\n",
      "Province                          0\n",
      "PostalCode                        0\n",
      "MainCrestaZone                    0\n",
      "SubCrestaZone                     0\n",
      "ItemType                          0\n",
      "mmcode                            0\n",
      "VehicleType                       0\n",
      "RegistrationYear                  0\n",
      "make                              0\n",
      "Model                             0\n",
      "Cylinders                         0\n",
      "cubiccapacity                     0\n",
      "kilowatts                         0\n",
      "bodytype                          0\n",
      "NumberOfDoors                     0\n",
      "VehicleIntroDate                  0\n",
      "CustomValueEstimate               0\n",
      "AlarmImmobiliser                  0\n",
      "TrackingDevice                    0\n",
      "CapitalOutstanding                0\n",
      "NewVehicle                        0\n",
      "WrittenOff                        0\n",
      "Rebuilt                           0\n",
      "Converted                         0\n",
      "CrossBorder                       0\n",
      "NumberOfVehiclesInFleet     1000098\n",
      "SumInsured                        0\n",
      "TermFrequency                     0\n",
      "CalculatedPremiumPerTerm          0\n",
      "ExcessSelected                    0\n",
      "CoverCategory                     0\n",
      "CoverType                         0\n",
      "CoverGroup                        0\n",
      "Section                           0\n",
      "Product                           0\n",
      "StatutoryClass                    0\n",
      "StatutoryRiskType                 0\n",
      "TotalPremium                      0\n",
      "TotalClaims                       0\n",
      "Profit                            0\n",
      "ClaimRatio                   381484\n",
      "VehicleAge                        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Impute missing numerical data with median\n",
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "df[numeric_cols] = df[numeric_cols].fillna(df[numeric_cols].median())\n",
    "\n",
    "# For categorical columns, fill missing values with mode\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "# Calculating 'Profit' and 'ClaimRatio'\n",
    "df['Profit'] = df['TotalPremium'] - df['TotalClaims']\n",
    "df['ClaimRatio'] = df['TotalClaims'] / df['TotalPremium']\n",
    "\n",
    "# Calculating 'VehicleAge'\n",
    "df['VehicleAge'] = 2024 - df['RegistrationYear']\n",
    "\n",
    "# Verify changes\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "\n",
    "# One-hot encode categorical columns\n",
    "df_encoded = pd.get_dummies(df, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_encoded.drop(columns=['TotalPremium', 'TotalClaims'])\n",
    "y_premium = df_encoded['TotalPremium']\n",
    "y_claims = df_encoded['TotalClaims']\n",
    "\n",
    "# Split for TotalPremium\n",
    "X_train_premium, X_test_premium, y_train_premium, y_test_premium = train_test_split(X, y_premium, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split for TotalClaims\n",
    "X_train_claims, X_test_claims, y_train_claims, y_test_claims = train_test_split(X, y_claims, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Linear regression for TotalPremium\n",
    "lr_model_premium = LinearRegression()\n",
    "lr_model_premium.fit(X_train_premium, y_train_premium)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_premium = lr_model_premium.predict(X_test_premium)\n",
    "mse_premium = mean_squared_error(y_test_premium, y_pred_premium)\n",
    "print(f'Linear Regression MSE for TotalPremium: {mse_premium}')\n",
    "\n",
    "# Linear regression for TotalClaims\n",
    "lr_model_claims = LinearRegression()\n",
    "lr_model_claims.fit(X_train_claims, y_train_claims)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_claims = lr_model_claims.predict(X_test_claims)\n",
    "mse_claims = mean_squared_error(y_test_claims, y_pred_claims)\n",
    "print(f'Linear Regression MSE for TotalClaims: {mse_claims}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Random Forest for TotalPremium\n",
    "rf_model_premium = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model_premium.fit(X_train_premium, y_train_premium)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_rf_premium = rf_model_premium.predict(X_test_premium)\n",
    "mse_rf_premium = mean_squared_error(y_test_premium, y_pred_rf_premium)\n",
    "print(f'Random Forest MSE for TotalPremium: {mse_rf_premium}')\n",
    "\n",
    "# Random Forest for TotalClaims\n",
    "rf_model_claims = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "rf_model_claims.fit(X_train_claims, y_train_claims)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_rf_claims = rf_model_claims.predict(X_test_claims)\n",
    "mse_rf_claims = mean_squared_error(y_test_claims, y_pred_rf_claims)\n",
    "print(f'Random Forest MSE for TotalClaims: {mse_rf_claims}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# XGBoost for TotalPremium\n",
    "xg_model_premium = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "xg_model_premium.fit(X_train_premium, y_train_premium)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_xg_premium = xg_model_premium.predict(X_test_premium)\n",
    "mse_xg_premium = mean_squared_error(y_test_premium, y_pred_xg_premium)\n",
    "print(f'XGBoost MSE for TotalPremium: {mse_xg_premium}')\n",
    "\n",
    "# XGBoost for TotalClaims\n",
    "xg_model_claims = xgb.XGBRegressor(n_estimators=100, random_state=42)\n",
    "xg_model_claims.fit(X_train_claims, y_train_claims)\n",
    "\n",
    "# Predictions and evaluation\n",
    "y_pred_xg_claims = xg_model_claims.predict(X_test_claims)\n",
    "mse_xg_claims = mean_squared_error(y_test_claims, y_pred_xg_claims)\n",
    "print(f'XGBoost MSE for TotalClaims: {mse_xg_claims}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
